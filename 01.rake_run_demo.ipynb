{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rake_cn import * #which version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_short_text(path='./samples/4.cn_property_burst.txt'):\n",
    "    f=open(path)\n",
    "    text=f.readlines()\n",
    "    text=''.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_list_text(text_list):\n",
    "    for item in text_list:\n",
    "        if(type(item)==tuple):\n",
    "            print item[0],item[1]\n",
    "        else:\n",
    "            print item\n",
    "def return_segs(line):\n",
    "    tk=tokenizer()\n",
    "    tokens=tk.tokenize(line)\n",
    "    natures=tk.tokenize_nature(line)\n",
    "    return zip(tokens,natures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_keyword(text,limit=5):\n",
    "    sentences=split_sentences(text)\n",
    "    phrase_list = generate_candidate_keywords(sentences, stop_words_pattern)\n",
    "    word_scores = calculate_word_scores(phrase_list)\n",
    "    keyword_candidates = generate_candidate_keyword_scores(phrase_list, word_scores)\n",
    "    sorted_keywords = sorted(keyword_candidates.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    sorted_keywords_filtered = filter(lambda x: len(x[0])>3*1 and len(x[0])<3*9 and '\\n' not in x[0],sorted_keywords)\n",
    "    return sorted_keywords_filtered[:limit]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = read_short_text('./samples/4.cn_property_burst.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words_pattern=build_stop_word_regex('./stopwords/cn_stopword_list_1208.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences=split_sentences(text)\n",
    "phrase_list = generate_candidate_keywords(sentences, stop_words_pattern)\n",
    "word_scores = calculate_word_scores(phrase_list)\n",
    "keyword_candidates = generate_candidate_keyword_scores(phrase_list, word_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_list_text(phrase_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_keywords = sorted(keyword_candidates.iteritems(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_keywords_filtered = filter(lambda x: len(x[0])>2*1 and len(x[0])<3*9 and '\\n' not in x[0],sorted_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "减少居民购房套数 13.8\n",
      "揭秘房价崩溃 12.7142857143\n",
      "资产价位低 8.4\n",
      "基础设施投资 8.25\n",
      "金融调控放宽时 7.5\n",
      "投资渠道少 7.25\n",
      "线城市厦门 7.0\n",
      "调控措施抑制房价 6.46428571429\n",
      "资产价格泡沫 6.22142857143\n",
      "产热崩溃 5.0\n",
      "资产价格 4.65\n",
      "收紧时 4.5\n",
      "刺激住房 4.33333333333\n",
      "投资渠道 4.25\n",
      "央行放宽 4.0\n",
      "够健全 4.0\n",
      "华工作 4.0\n",
      "抵押贷款利率 4.0\n"
     ]
    }
   ],
   "source": [
    "for item in sorted_keywords_filtered[:18]:\n",
    "    print item[0],item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding extract rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk=tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "减少居民购房套数 13.8\n",
      "调控措施抑制房价 6.46428571429\n",
      "刺激住房 4.33333333333\n",
      "相关图集 4.0\n"
     ]
    }
   ],
   "source": [
    "out_list=[]\n",
    "for item in sorted_keywords_filtered[:20]:   \n",
    "    re = return_segs(item[0])\n",
    "    natures=pd.DataFrame(re)[1].tolist()\n",
    "    if(('n' in natures or 'NNT' in natures) and 'v' in natures):\n",
    "        out_list.append(item)\n",
    "        if(natures.count('v')>1 and (natures.count('n') + natures.count('NNT'))==1): ## 不出现两个动词\n",
    "            out_list.remove(item)\n",
    "        if(natures[-1]=='d'):   ## 不以副词结尾\n",
    "            out_list.remove(item)\n",
    "        if(natures[0]=='j'): ## 简称略语 开头\n",
    "            out_list.remove(item)\n",
    "print_list_text(out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_rules(sorted_keywords_filtered):\n",
    "    out_list=[]\n",
    "    for item in sorted_keywords_filtered[:20]:\n",
    "        try:\n",
    "            re = return_segs(item[0])\n",
    "            natures=pd.DataFrame(re)[1].tolist()\n",
    "            words=pd.DataFrame(re)[0].tolist()\n",
    "        except:\n",
    "            continue\n",
    "        if(('n' in natures or 'NNT' in natures) and 'v' in natures):\n",
    "            out_list.append(item)\n",
    "            if(natures.count('v')>1 and (natures.count('n') + natures.count('NNT'))==1): ## 不出现两个动词\n",
    "                out_list.remove(item)\n",
    "                continue\n",
    "            if(natures[-1]=='d'):  ## 不以副词结尾\n",
    "                out_list.remove(item)\n",
    "                continue\n",
    "            if(natures[0]=='j'): ## 简称略语 开头\n",
    "                out_list.remove(item)\n",
    "                continue\n",
    "            if(len(words[0])==1 and natures[0]!='a'):# 第一个字,不可以不是形容词\n",
    "                out_list.remove(item)\n",
    "                continue\n",
    "            if(len(words[-1])==1 and natures[-1]=='v'):#最后一个字,不可以是动词\n",
    "                out_list.remove(item)\n",
    "                continue\n",
    "            if(len(words[-1])==1 and natures[-1]=='a'):#最后一个字,不可以是形容词\n",
    "                out_list.remove(item)\n",
    "                continue\n",
    "    print_list_text(out_list)\n",
    "    return out_list\n",
    "noun_set=set(['nw','ns','n','vn','NNT','FINANCIAL','STOCK'])\n",
    "def check_rules2(sorted_keywords_filtered):\n",
    "    tk = tokenizer()\n",
    "    out_list=[]\n",
    "    for item in sorted_keywords_filtered[:20]:\n",
    "        try:\n",
    "            re = return_segs(item[0])\n",
    "            re = pd.DataFrame(re)\n",
    "            re.columns=['w','n']\n",
    "        except:\n",
    "            continue\n",
    "        out=None\n",
    "        for row in re.itertuples():\n",
    "            nat=row.n\n",
    "            word=row.w\n",
    "            if(nat in noun_set):\n",
    "                if(len(word)==1):\n",
    "                    continue\n",
    "                if(out is not None):\n",
    "                    out=out+word\n",
    "                else:\n",
    "                    out=word\n",
    "            if(nat not in noun_set):\n",
    "                if(out is not None):\n",
    "                    out_list.append(out)\n",
    "                    out=None\n",
    "                out=None\n",
    "        if(out is not None):\n",
    "            out_list.append(out)\n",
    "    for item in out_list:\n",
    "        #print item,len(tk.tokenize(item))\n",
    "        if(len(item)==3 and len(tk.tokenize(item))>1):\n",
    "            out_list.remove(item)\n",
    "    #print_list_text(out_list)\n",
    "    return out_list\n",
    "\n",
    "def check_rules3(sorted_keywords_filtered):  ## 包含名词, 不以单个词开头或结尾,不包含完整主谓宾\n",
    "    tk = tokenizer()\n",
    "    out_list=[]\n",
    "    for item in sorted_keywords_filtered[:20]:\n",
    "        try:\n",
    "            if(item[1]<4): ##score threshold\n",
    "                continue\n",
    "            re = return_segs(item[0])\n",
    "            re = pd.DataFrame(re)\n",
    "            re.columns=['w','n']\n",
    "        except:\n",
    "            continue\n",
    "        out=None\n",
    "        none_flag = False\n",
    "        words=[]\n",
    "        nats=[]\n",
    "        for row in re.itertuples():\n",
    "            nat=row.n\n",
    "            word=row.w\n",
    "            words.append(word)\n",
    "            nats.append(nat)\n",
    "            if(nat in noun_set):\n",
    "                none_flag = True\n",
    "        if(nats[-1]=='an' or nats[-1]=='a'):\n",
    "            words=words[:-1]\n",
    "            nats=nats[:-1]\n",
    "            if(len(words)<1):\n",
    "                continue\n",
    "        if(len(words[-1])==1):\n",
    "            words=words[:-1]\n",
    "            nats=nats[:-1]\n",
    "            if(len(words)<1):\n",
    "                continue\n",
    "        if(len(words[0])==1):\n",
    "            words=words[1:]\n",
    "            nats=nats[1:]\n",
    "            if(len(words)<1):\n",
    "                continue\n",
    "        elif(nats[0]=='v'):\n",
    "            words=words[1:]\n",
    "            nats=nats[1:]\n",
    "            if(len(words)<1):\n",
    "                continue\n",
    "        \n",
    "        out = ''.join(words)\n",
    "        \n",
    "        if(len(words)==1 and nats[0]=='vn'):\n",
    "            none_flag = False\n",
    "        if(len(nats)>=4 and ('vn' in set(nats) or 'v' in set(nats))):\n",
    "            none_flag = False\n",
    "        if(len(nats)>=1 and nats[0]=='v' and len(words[0])==1):\n",
    "            none_flag = False\n",
    "        if(len(nats)>=3 and nats[0] in noun_set and ('vn' in set(nats[1:-1]) or 'v' in set(nats[1:-1])) and nats[-1] in noun_set):##filter out nvn\n",
    "            none_flag = False\n",
    "        if(len(words)==1 and len(words[0])==1):\n",
    "            none_flag = False\n",
    "        if(none_flag and len(out)<7):\n",
    "            out_list.append(out)\n",
    "        \n",
    "    \n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## on our news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: 中城投资2016年上半年营收4.1亿元净赚1.2亿元 \n",
      "\n",
      "content: 　　 9月26日消息，中城投资（证券代码：833880）近日公布的2016年上半年报告显示，报告期内实现营收4.08亿元，较上年同期增长8.35%；归属于挂牌公司股东的净利润为1.15亿元，较上年同期下降12.75%；基本每股收益为0.07元，较上年同期下降12.50%。 　　截止2016年6月30日，中城投资资产总计为67.94亿元，较本期期初下降19.48%；资产负债率为67.29%，较本期期初72.56%，下滑5.27个百分点。经营活动产生的现金流量净额本期为4.58亿元，上年同期为1.53亿元。 　　报告期内，中城投资经营情况变化的主要原因为市场处于利率下行通道，公司投资的收益率水平下降；中城投资降低了杠杆，同时也降低了自有资金投资规模，自有投资规模由年初的43.54亿元下降至30.69亿元，融资余额从年初的35.28亿元下降至23.06亿元；中城投资基金管理规模及收入较上年度同期有小幅增长，主要是由于实现的业绩报酬增加，但由于管理投入增加，业务成本较上年度增加，导致基金管理收入的毛利率下降。 　　中城投资经营性现金流分析：由于各板块业务收入增加，再加之提前收回财政返还，较上年度同期有大幅增加，2016年上半年，中城投资秉承经营安全的理念，保证充裕的现金流，同时积极回报股东，完成现金分配2.05亿元。 　　据挖贝新三板研究院资料显示，中城投资是一家专注于房地产领域的专业投资管理控股公司|中城投资以房地产全价值链和相关新产业链投资为特色|通过运营下辖多个业务板块，对不同的业务板块实施分类管理，为客户提供专业的咨询与管理服务，为投资人创造价值。 　　报告期内部分重要事项：  \n",
      "\n",
      "key_words: 财政 全价值链 通道 现金分配 益率水平 价值\n"
     ]
    }
   ],
   "source": [
    "print_title_content_key_words(index=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:top-env]",
   "language": "python",
   "name": "conda-env-top-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
